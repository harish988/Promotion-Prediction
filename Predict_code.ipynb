{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravichandran\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown metric function:f1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2d89de804378>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'glorot_uniform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_updates\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[0mhandle_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m         \u001b[0mhandle_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[1;34m(metrics, weights)\u001b[0m\n\u001b[0;32m    509\u001b[0m                   metric_fn)\n\u001b[0;32m    510\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               \u001b[0mmetric_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m               weighted_metric_fn = training_utils.weighted_masked_objective(\n\u001b[0;32m    513\u001b[0m                   metric_fn)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0midentifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     98\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m       printable_module_name='metric function')\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    191\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         raise ValueError('Unknown ' + printable_module_name + ':' +\n\u001b[1;32m--> 193\u001b[1;33m                          function_name)\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown metric function:f1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#importing training data\n",
    "dataset = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X_train = dataset.iloc[:,1:13].values\n",
    "y_train = dataset.iloc[:,13].values\n",
    "\n",
    "#Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder_dept = LabelEncoder()\n",
    "X_train[:, 0] = label_encoder_dept.fit_transform(X_train[:, 0].astype(str))\n",
    "\n",
    "label_encoder_reg = LabelEncoder()\n",
    "X_train[:, 1] = label_encoder_reg.fit_transform(X_train[:, 1].astype(str))\n",
    "\n",
    "label_encoder_edu = LabelEncoder()\n",
    "X_train[:, 2] = label_encoder_edu.fit_transform(X_train[:, 2].astype(str))\n",
    "\n",
    "label_encoder_gen = LabelEncoder()\n",
    "X_train[:, 3] = label_encoder_gen.fit_transform(X_train[:, 3].astype(str))\n",
    "\n",
    "label_encoder_rec = LabelEncoder()\n",
    "X_train[:, 4] = label_encoder_rec.fit_transform(X_train[:, 4].astype(str))\n",
    "\n",
    "\n",
    "#Handling missing data\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 0:1])\n",
    "X_train[:, 0:1] = imputer.transform(X_train[:, 0:1])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 1:2])\n",
    "X_train[:, 1:2] = imputer.transform(X_train[:, 1:2])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 2:3])\n",
    "X_train[:, 2:3] = imputer.transform(X_train[:, 2:3])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 3:4])\n",
    "X_train[:, 3:4] = imputer.transform(X_train[:, 3:4])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 4:5])\n",
    "X_train[:, 4:5] = imputer.transform(X_train[:, 4:5])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 5:6])\n",
    "X_train[:, 5:6] = imputer.transform(X_train[:, 5:6])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 6:7])\n",
    "X_train[:, 6:7] = imputer.transform(X_train[:, 6:7])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 7:8])\n",
    "X_train[:, 7:8] = imputer.transform(X_train[:, 7:8])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 8:9])\n",
    "X_train[:, 8:9] = imputer.transform(X_train[:, 8:9])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 9:10])\n",
    "X_train[:, 9:10] = imputer.transform(X_train[:, 9:10])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 10:11])\n",
    "X_train[:, 10:11] = imputer.transform(X_train[:, 10:11])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X_train[:, 11:12])\n",
    "X_train[:, 11:12] = imputer.transform(X_train[:, 11:12])\n",
    "\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "imputer_y_train = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer_y_train = imputer_y_train.fit(y_train[:])\n",
    "y_train[:] = imputer_y_train.transform(y_train[:])\n",
    "\n",
    "\n",
    "#importing testing data\n",
    "dataset_test = pd.read_csv(\"test.csv\")\n",
    "X_test = dataset_test.iloc[:,1:13].values\n",
    "y_test = dataset_test.iloc[:,12].values\n",
    "\n",
    "#Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder_dept = LabelEncoder()\n",
    "X_test[:, 0] = label_encoder_dept.fit_transform(X_test[:, 0].astype(str))\n",
    "\n",
    "label_encoder_reg = LabelEncoder()\n",
    "X_test[:, 1] = label_encoder_reg.fit_transform(X_test[:, 1].astype(str))\n",
    "\n",
    "label_encoder_edu = LabelEncoder()\n",
    "X_test[:, 2] = label_encoder_edu.fit_transform(X_test[:, 2].astype(str))\n",
    "\n",
    "label_encoder_gen = LabelEncoder()\n",
    "X_test[:, 3] = label_encoder_gen.fit_transform(X_test[:, 3].astype(str))\n",
    "\n",
    "label_encoder_rec = LabelEncoder()\n",
    "X_test[:, 4] = label_encoder_rec.fit_transform(X_test[:, 4].astype(str))\n",
    "\n",
    "\n",
    "#Handling missing data\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 0:1])\n",
    "X_test[:, 0:1] = imputer.transform(X_test[:, 0:1])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 1:2])\n",
    "X_test[:, 1:2] = imputer.transform(X_test[:, 1:2])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 2:3])\n",
    "X_test[:, 2:3] = imputer.transform(X_test[:, 2:3])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 3:4])\n",
    "X_test[:, 3:4] = imputer.transform(X_test[:, 3:4])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 4:5])\n",
    "X_test[:, 4:5] = imputer.transform(X_test[:, 4:5])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 5:6])\n",
    "X_test[:, 5:6] = imputer.transform(X_test[:, 5:6])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 6:7])\n",
    "X_test[:, 6:7] = imputer.transform(X_test[:, 6:7])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 7:8])\n",
    "X_test[:, 7:8] = imputer.transform(X_test[:, 7:8])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 8:9])\n",
    "X_test[:, 8:9] = imputer.transform(X_test[:, 8:9])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 9:10])\n",
    "X_test[:, 9:10] = imputer.transform(X_test[:, 9:10])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 10:11])\n",
    "X_test[:, 10:11] = imputer.transform(X_test[:, 10:11])\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X_test[:, 11:12])\n",
    "X_test[:, 11:12] = imputer.transform(X_test[:, 11:12])\n",
    "\n",
    "\n",
    "y_test = y_test.reshape(-1,1)\n",
    "imputer_y_test = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imputer_y_test = imputer_y_test.fit(y_test[:])\n",
    "y_test[:] = imputer_y_test.transform(y_test[:])\n",
    "\n",
    "\n",
    "\n",
    "#Construction of ANN\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.layers import Dropout\n",
    "classifier = keras.Sequential()\n",
    "classifier.add(keras.layers.Dense(activation='relu',units = 10, input_dim = 12, kernel_initializer = 'glorot_uniform' ))\n",
    "classifier.add(keras.layers.Dropout(rate = 0.4))\n",
    "classifier.add(keras.layers.Dense(activation='sigmoid',units = 8, kernel_initializer = 'glorot_uniform'))\n",
    "classifier.add(keras.layers.Dropout(rate=0.3))\n",
    "classifier.add(keras.layers.Dense(activation='sigmoid',units = 1, kernel_initializer = 'glorot_uniform'))\n",
    "classifier.compile(optimizer='rmsprop', loss='binary_crossentropy',metrics=['f1'])\n",
    "classifier.fit(X_train,y_train,batch_size=10, epochs=100)\n",
    "\n",
    "#predicting the result\n",
    "y_pred = classifier.predict(X_test) \n",
    "\n",
    "y_pred= list(map(np.round,y_pred))\n",
    "emp = dataset_test.iloc[:,0].values\n",
    "\n",
    "import csv\n",
    "with open(\"submission.csv\",'w',encoding='utf-8',newline='') as outfile:\n",
    "    mywriter = csv.writer(outfile)\n",
    "    #manually add header\n",
    "    mywriter.writerow(['employee_id','is_promoted'])\n",
    "    for i in range(len(y_pred)):\n",
    "        res = []\n",
    "        res.append(emp[i])\n",
    "        res.append(''.join(map(str, y_pred[i])))\n",
    "        mywriter.writerow(res)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
